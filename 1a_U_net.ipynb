{"cells":[{"cell_type":"markdown","metadata":{"id":"HBbQ4K3Atek5"},"source":["# U-net 1"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"jfevpf6fDksY"},"outputs":[{"name":"stdout","output_type":"stream","text":["\u001b[K     |████████████████████████████████| 631 kB 31.9 MB/s \n","\u001b[?25h  Building wheel for imgaug (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Building wheel for tensorflow-examples (setup.py) ... \u001b[?25l\u001b[?25hdone\n","\u001b[33m  WARNING: Built wheel for tensorflow-examples is invalid: Metadata 1.2 mandates PEP 440 version, but 'ca5a4fbbc7df097ec3110fe4c1f51e77897819f8-' is not\u001b[0m\n","    Running setup.py install for tensorflow-examples ... \u001b[?25l\u001b[?25hdone\n","\u001b[33m  DEPRECATION: tensorflow-examples was installed using the legacy 'setup.py install' method, because a wheel could not be built for it. A possible replacement is to fix the wheel build issue reported above. You can find discussion regarding this at https://github.com/pypa/pip/issues/8368.\u001b[0m\n","\u001b[K     |████████████████████████████████| 1.1 MB 35.0 MB/s \n","\u001b[K     |████████████████████████████████| 50 kB 7.9 MB/s \n","\u001b[?25h"]}],"source":["!pip install albumentations --quiet\n","!pip install git+https://github.com/tensorflow/examples.git --quiet\n","!pip install tensorflow_addons --quiet\n","!pip install segmentation-models --quiet"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"GuIMFCcQs4Lk"},"outputs":[],"source":["import tensorflow as tf\n","from tensorflow import keras\n","from matplotlib import pyplot as plt\n","from shutil import copyfile\n","import numpy as np\n","import scipy.io\n","from tensorflow.keras import layers\n","import glob\n","import imageio\n","import os\n","import PIL\n","import time\n","from IPython import display\n","import albumentations as A\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","import cv2 as cv\n","import datetime\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D, concatenate, Conv2DTranspose, BatchNormalization, Dropout, Lambda, Activation, MaxPool2D, Concatenate\n","from tensorflow.keras.optimizers import Adam\n","from tensorflow.keras.utils import to_categorical\n","from sklearn.utils.class_weight import compute_class_weight\n","from IPython.display import clear_output\n","from sklearn.preprocessing import LabelEncoder\n","from tensorflow_examples.models.pix2pix import pix2pix\n","import tensorflow_addons as tfa\n","from keras import backend as K"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"6-1TUNqDD_-4"},"outputs":[],"source":["# from google.colab import drive\n","# drive.mount('/content/gdrive')\n","# copyfile('gdrive/My Drive/DEEP-project/Progetto_DL_finale/immagini2000.npy', 'immagini2000.npy')\n","# copyfile('gdrive/My Drive/DEEP-project/Progetto_DL_finale/maschere2000.npy', 'maschere2000.npy')\n","# copyfile('gdrive/My Drive/DEEP-project/Progetto_DL_finale/X_val.npy', 'X_val.npy')\n","# copyfile('gdrive/My Drive/DEEP-project/Progetto_DL_finale/y_val.npy', 'y_val.npy')"]},{"cell_type":"markdown","metadata":{"id":"QDhfN5CO3ukq"},"source":["#### Train set"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"_hxDCn1xLsv3"},"outputs":[],"source":["num = 1600"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"n7jVVnz832eL"},"outputs":[],"source":["n_classes=19"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"UnuqpjD2NT6R"},"outputs":[{"ename":"FileNotFoundError","evalue":"ignored","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m\u003cipython-input-6-b25bae3a7910\u003e\u001b[0m in \u001b[0;36m\u003cmodule\u003e\u001b[0;34m()\u001b[0m\n\u001b[0;32m----\u003e 1\u001b[0;31m \u001b[0mX_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'immagini2000.npy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mnum\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0my_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'maschere2000.npy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mnum\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(file, mmap_mode, allow_pickle, fix_imports, encoding)\u001b[0m\n\u001b[1;32m    415\u001b[0m             \u001b[0mown_fid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    416\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--\u003e 417\u001b[0;31m             \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstack\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menter_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos_fspath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    418\u001b[0m             \u001b[0mown_fid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    419\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'immagini2000.npy'"]}],"source":["X_train = np.load('immagini2000.npy')[0:num,:,:,:]\n","y_train = np.array(tf.expand_dims(np.load('maschere2000.npy')[0:num,:,:],3))"]},{"cell_type":"markdown","metadata":{"id":"tUItlpGiCan1"},"source":["#### Categorizzare train set"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"DLqv5Ryt3yAY"},"outputs":[],"source":["train_masks_cat = to_categorical(y_train, num_classes=n_classes)\n","y_train_cat = train_masks_cat.reshape((y_train.shape[0], y_train.shape[1], y_train.shape[2], n_classes))\n","y_train = 0\n","train_masks_cat = 0"]},{"cell_type":"markdown","metadata":{"id":"Xq_XBQXew0OK"},"source":["#### Validation set"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"QVAdT7obxFGO"},"outputs":[],"source":["n_classes = 19"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"55FYhSeC5BHY"},"outputs":[],"source":["# num_val = 980\n","# num_val2 = np.random.permutation(np.arange(num_val))[0:200]"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"F8BqHRxc2zEx"},"outputs":[],"source":["# X_val = np.load('X_val.npy')[0:num_val,:,:,:]\n","# X_val = X_val/X_val.max()\n","# y_val = np.array(tf.expand_dims(np.load('y_val.npy')[0:num_val,:,:],3))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"5J-bEWe3SSe7"},"outputs":[],"source":["# lista1 = []\n","# lista2 = []\n","# for i in num_val2:\n","#   lista1.append(X_val[i,...])\n","#   lista2.append(y_val[i,...])\n","# X_val=np.array(lista1)\n","# y_val=np.array(lista2)\n","# num_val2 = 0"]},{"cell_type":"markdown","metadata":{"id":"KDVLuF3ACgPD"},"source":["#### Categorizzare validation set"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"MmqiBe3j30TO"},"outputs":[],"source":["# train_masks_cat = to_categorical(y_val, num_classes=n_classes)\n","# y_val_cat = train_masks_cat.reshape((y_val.shape[0], y_val.shape[1], y_val.shape[2], n_classes))\n","# y_val = 0\n","# train_masks_cat = 0"]},{"cell_type":"markdown","metadata":{"id":"nusovNENE93B"},"source":["#### Data loader"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"9UPLhuhcGZe7"},"outputs":[],"source":["batch_size = 8"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"gKFLxrLVGW3e"},"outputs":[],"source":["class DataGenerator(keras.utils.Sequence):\n","  def __init__(self, x_data, y_data, batch_size):\n","    self.x, self.y = x_data, y_data\n","    self.batch_size = batch_size\n","    self.num_batches = np.ceil(len(x_data) / batch_size)\n","    self.batch_idx = np.array_split(range(len(x_data)), self.num_batches)\n","\n","  def __len__(self):\n","    return len(self.batch_idx)\n","\n","  def __getitem__(self, idx):\n","    batch_x = self.x[self.batch_idx[idx]]\n","    batch_y = self.y[self.batch_idx[idx]]\n","    return batch_x, batch_y"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"2OdW_z7XE9ev"},"outputs":[],"source":["train_generator = DataGenerator(X_train, y_train_cat, batch_size = batch_size)\n","#val_generator = DataGenerator(X_val, y_val_cat, batch_size = batch_size)"]},{"cell_type":"markdown","metadata":{"id":"D9scbImuVVa3"},"source":["### U-net"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"_jB4jXpYUz_J"},"outputs":[],"source":["def multi_unet_model(n_classes=19, IMG_HEIGHT=256, IMG_WIDTH=256, IMG_CHANNELS=6):\n","#Build the model\n","    inputs = Input((IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS))\n","    #s = Lambda(lambda x: x / 255)(inputs)   #No need for this if we normalize our inputs beforehand\n","    s = inputs\n","\n","    #Contraction path\n","    c1 = Conv2D(16, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(s)\n","    c1 = Dropout(0.1)(c1)\n","    c1 = Conv2D(16, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c1)\n","    c1 = BatchNormalization()(c1)\n","    p1 = MaxPooling2D((2, 2))(c1)\n","    \n","    c2 = Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(p1)\n","    c2 = Dropout(0.1)(c2)\n","    c2 = Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c2)\n","    c2 = BatchNormalization()(c2)\n","    p2 = MaxPooling2D((2, 2))(c2)\n","     \n","    c3 = Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(p2)\n","    c3 = Dropout(0.2)(c3)\n","    c3 = Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c3)\n","    c3 = BatchNormalization()(c3)\n","    p3 = MaxPooling2D((2, 2))(c3)\n","     \n","    c4 = Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(p3)\n","    c4 = Dropout(0.2)(c4)\n","    c4 = Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c4)\n","    c4 = BatchNormalization()(c4)\n","    p4 = MaxPooling2D(pool_size=(2, 2))(c4)\n","     \n","    c5 = Conv2D(256, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(p4)\n","    c5 = Dropout(0.3)(c5)\n","    c5 = Conv2D(256, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c5)\n","    \n","    #Expansive path \n","    u6 = Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(c5)\n","    u6 = concatenate([u6, c4])\n","    c6 = Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(u6)\n","    c6 = Dropout(0.2)(c6)\n","    c6 = Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c6)\n","    c6 = BatchNormalization()(c6)\n","     \n","    u7 = Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(c6)\n","    u7 = concatenate([u7, c3])\n","    c7 = Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(u7)\n","    c7 = Dropout(0.2)(c7)\n","    c7 = Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c7)\n","    c7 = BatchNormalization()(c7)\n","     \n","    u8 = Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same')(c7)\n","    u8 = concatenate([u8, c2])\n","    c8 = Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(u8)\n","    c8 = Dropout(0.1)(c8)\n","    c8 = Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c8)\n","    c8 = BatchNormalization()(c8)\n","     \n","    u9 = Conv2DTranspose(16, (2, 2), strides=(2, 2), padding='same')(c8)\n","    u9 = concatenate([u9, c1], axis=3)\n","    c9 = Conv2D(16, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(u9)\n","    c9 = Dropout(0.1)(c9)\n","    c9 = Conv2D(16, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c9)\n","    c9 = BatchNormalization()(c9)\n","     \n","    outputs = Conv2D(n_classes, (1, 1), activation='softmax')(c9)\n","     \n","    model = Model(inputs=[inputs], outputs=[outputs])\n","    \n","    #NOTE: Compile the model in the main program to make it easy to test with various loss functions\n","    #model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n","    \n","    #model.summary()\n","    \n","    return model"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"b5m_vip7wOR1"},"outputs":[],"source":["IMG_HEIGHT = X_train.shape[1]\n","IMG_WIDTH  = X_train.shape[2]\n","IMG_CHANNELS = X_train.shape[3]\n","\n","def get_model():\n","    return multi_unet_model(n_classes=n_classes, IMG_HEIGHT=IMG_HEIGHT, IMG_WIDTH=IMG_WIDTH, IMG_CHANNELS=IMG_CHANNELS)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"dkpaEqmfJb5I"},"outputs":[],"source":["def focal_loss(gamma=2., alpha=.25):\n","\tdef focal_loss_fixed(y_true, y_pred):\n","\t\tpt_1 = tf.where(tf.equal(y_true, 1), y_pred, tf.ones_like(y_pred))\n","\t\tpt_0 = tf.where(tf.equal(y_true, 0), y_pred, tf.zeros_like(y_pred))\n","\t\treturn -K.mean(alpha * K.pow(1. - pt_1, gamma) * K.log(pt_1+K.epsilon())) - K.mean((1 - alpha) * K.pow(pt_0, gamma) * K.log(1. - pt_0 + K.epsilon()))\n","\treturn focal_loss_fixed"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"-1Tokxx9wcXi"},"outputs":[],"source":["model = get_model()\n","model.compile(optimizer='adam', loss=focal_loss(), metrics=[tf.keras.metrics.Recall(),\n","                                                          tf.keras.metrics.Precision(),\n","                                                          tf.keras.metrics.OneHotMeanIoU(num_classes=n_classes),\n","                                                          'accuracy'])\n","#tfa.losses.SigmoidFocalCrossEntropy(), 'categorical_crossentropy', focal_loss\n","#model.summary()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"EA8Oc7eXlwzk"},"outputs":[],"source":["#tf.keras.utils.plot_model(model, to_file='1a_U-net.png',show_shapes=True, dpi=1028)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"JN4ithg8qxUN"},"outputs":[],"source":["callback = keras.callbacks.EarlyStopping(monitor='train_loss', patience=5) #val_one_hot_mean_io_u"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"U_tngVpelzoI"},"outputs":[],"source":["def create_mask(pred_mask):\n","  pred_mask = tf.argmax(pred_mask, axis=-1)\n","  pred_mask = pred_mask[..., tf.newaxis]\n","  return pred_mask[0]"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"ksG9FIBVtjbj"},"outputs":[],"source":["# k = 87\n","# sample_image, sample_mask = X_val[k,:,:,:], create_mask(tf.expand_dims(y_val_cat[k,:,:,:],0)) \n","k = 87\n","sample_image, sample_mask = X_train[k,:,:,:], create_mask(tf.expand_dims(y_train_cat[k,:,:,:],0)) "]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"Ni2GE-reBpaf"},"outputs":[],"source":["def display(display_list):\n","  plt.figure(figsize=(15, 15))\n","\n","  title = ['Input Image', 'True Mask', 'Predicted Mask']\n","\n","  for i in range(len(display_list)):\n","    plt.subplot(1, len(display_list), i+1)\n","    plt.title(title[i])\n","    if i==0:\n","      plt.imshow(tf.keras.preprocessing.image.array_to_img(display_list[i]))\n","    else:\n","      plt.imshow(display_list[i])\n","\n","    plt.axis('off')\n","  plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"KEGekNve_hc9"},"outputs":[],"source":["def show_predictions(dataset=None, num=1):\n","  if dataset:\n","    for image, mask in dataset.take(num):\n","      pred_mask = model.predict(image)\n","      display([image[0], mask[0], create_mask(pred_mask)])\n","  else:\n","    display([sample_image[:,:,0:3], sample_mask[:,:,0], create_mask(model.predict(tf.expand_dims(sample_image,0)))[:,:,0]])"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"0cd-oCedrCYV"},"outputs":[],"source":["class DisplayCallback(tf.keras.callbacks.Callback):\n","  def on_epoch_end(self, epoch, logs=None):\n","    clear_output(wait=True)\n","    show_predictions()\n","    print ('\\nSample Prediction after epoch {}\\n'.format(epoch+1))"]},{"cell_type":"markdown","metadata":{"id":"ixLjuaK0js8H"},"source":["### Training"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"jJxRkO14whTf"},"outputs":[],"source":["history = model.fit(x = train_generator,\n","                    verbose=1, \n","                    epochs=50, \n","                    #validation_data = val_generator,\n","                    shuffle = True,\n","                    callbacks=[callback,DisplayCallback()]\n","                    )"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"jS1z9ImMxYIn"},"outputs":[],"source":["#plot the training and validation accuracy and loss at each epoch\n","loss = history.history['loss']\n","val_loss = history.history['val_loss']\n","epochs = range(1, len(loss) + 1)\n","plt.plot(epochs, loss, 'y', label='Training loss')\n","plt.plot(epochs, val_loss, 'r', label='Validation loss')\n","plt.title('Training and validation loss')\n","plt.xlabel('Epochs')\n","plt.ylabel('Loss')\n","plt.legend()\n","plt.show()\n","\n","plt.plot(epochs, history.history['one_hot_mean_io_u'], 'y')\n","plt.plot(epochs, history.history['val_one_hot_mean_io_u'], 'r')\n","plt.title('Training and validation hot io_u')\n","plt.xlabel('Epochs')\n","plt.ylabel('Accuracy')\n","plt.legend()\n","plt.show()\n","\n","plt.plot(epochs, history.history['precision'], 'y')\n","plt.plot(epochs, history.history['val_precision'], 'r')\n","plt.title('Training and validation precision')\n","plt.xlabel('Epochs')\n","plt.ylabel('Accuracy')\n","plt.legend()\n","plt.show()\n","\n","\n","plt.plot(epochs, history.history['recall'], 'y',)\n","plt.plot(epochs, history.history['val_recall'], 'r')\n","plt.title('Training and validation recall')\n","plt.xlabel('Epochs')\n","plt.ylabel('Accuracy')\n","plt.legend()\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"XKni0azQicrK"},"source":["Download and upload of the model"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"Gg7p9q0-3QTQ"},"outputs":[],"source":["json_model = model.to_json()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"r6JJPWUmhXxH"},"outputs":[],"source":["with open('U-net_1_aug.json', 'w') as json_file:\n","    json_file.write(json_model)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"q2K7SOggh5ms"},"outputs":[],"source":["model.save_weights('U-net_1_aug_weights.h5')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"4wJTN1gvcpqF"},"outputs":[],"source":["!cp U-net_1_aug.json \"gdrive/My Drive/dl-prog-pro/\""]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"9PPT9tWJc5kV"},"outputs":[],"source":["!cp U-net_1_aug_weights.h5 \"gdrive/My Drive/dl-prog-pro/\""]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"NrqGx-bNiInI"},"outputs":[],"source":["with open('U-net_1_aug.json', 'r') as json_file:\n","    json_savedModel = json_file.read()\n","net = tf.keras.models.model_from_json(json_savedModel)\n","net.load_weights('U-net_1_aug_weights.h5')"]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":["HBbQ4K3Atek5","QDhfN5CO3ukq","tUItlpGiCan1","Xq_XBQXew0OK","KDVLuF3ACgPD","nusovNENE93B","D9scbImuVVa3","ixLjuaK0js8H"],"machine_shape":"hm","name":"1a_U_net.ipynb","version":""},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}